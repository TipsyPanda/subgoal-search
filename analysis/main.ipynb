# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
from sklearn.linear_model import LinearRegression

# Load the data from your CSV files into pandas DataFrames
data_bfs = pd.read_csv('metrics_bfs.csv')
data_a_star_advanced = pd.read_csv('metrics_a_star_advanced.csv')
data_a_star_simple = pd.read_csv('metrics_a_star_simple.csv')
data_a_star_zero = pd.read_csv('metrics_a_star_zero.csv')

# Concatenate the two dataframes
data = pd.concat([data_bfs, data_a_star_advanced,data_a_star_simple,data_a_star_zero], ignore_index=True)
data.loc[data['method'] == 'A*_adv', 'solve_length'] += 1
data['difference'] = data['opt_solve'] - data['solve_length']




# Display the DataFrame to make sure everything is loaded properly
print(data.head())

# Calculate the average solve time and average nodes for each method
average_solve_time = data.groupby('method')['solve_time'].mean()
average_nodes = data.groupby('method')['nodes'].mean()
average_deviation = data.groupby('method')['difference'].mean()


# Combine the two series into a DataFrame
average_metrics = pd.concat([average_solve_time, average_nodes,average_deviation], axis=1)

# Display the DataFrame
print(average_metrics)
# Convert the DataFrame to LaTeX
latex_table = average_metrics.to_latex()

# Print the LaTeX table
print(latex_table)



# Set width of the bars
bar_width = 0.35

# Set position of the bars
r1 = np.arange(len(average_solve_time))
r2 = [x + bar_width for x in r1]

fig, ax1 = plt.subplots()


# Make the bar plot on the ax1
bars1 = ax1.bar(r1, average_solve_time, width=bar_width, alpha=0.7, label='Average Solve Time')
ax1.set_ylabel('Average Solve Time')

ax1.set_xlabel('Method')
ax1.set_xticks([r + bar_width/2 for r in range(len(average_solve_time))])
ax1.set_xticklabels(average_solve_time.index)

# Create a new Axes instance with a secondary y-axis
ax2 = ax1.twinx()
bars2 = ax2.bar(r2, average_nodes, width=bar_width, alpha=0.7, color='tab:orange', label='Average Nodes')
ax2.set_ylabel('Average Nodes')

fig.tight_layout()
fig.legend(loc="upper right", bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes)
plt.savefig('png/barplot.png', dpi=600)
plt.show()


# Create a scatter plot comparing the number of nodes to the solve time for each method
for method in data['method'].unique():
    method_data = data[data['method'] == method]
    plt.scatter(method_data['nodes'], method_data['solve_time'], label=method)
    
    # Fit a linear function to the data and plot it
    m, b = np.polyfit(method_data['nodes'], method_data['solve_time'], 1)
    plt.plot(method_data['nodes'], m * method_data['nodes'] + b, label=f"{method} Fit")

plt.xlabel('Nodes')
plt.ylabel('Solve Time')
plt.title('Solve Time vs Number of Nodes by Method')
plt.legend()
plt.savefig('png/scatterplot.png', dpi=600)
plt.show()



# Create a box plot to visualize the distribution of solve lengths for each method
data.boxplot(column='solve_length', by='method')
plt.title('Distribution of Solve Lengths by Method')
plt.ylabel('Solve Length')
plt.savefig('png/boxplot_solve_length.png', dpi=600)
plt.show()


# Create a list to store nodes for each method
nodes_by_method = [data[data['method'] == method]['nodes'] for method in data['method'].unique()]

# Create the labels list by getting unique methods
labels = data['method'].unique()

# Create the boxplot
plt.figure(figsize=(10, 6))
plt.boxplot(nodes_by_method, labels=labels, showfliers=False)
plt.title('Boxplot of Nodes Explored by Method (Outliers Removed)')
plt.ylabel('Nodes')
plt.savefig('png/boxplot_nodes.png', dpi=600)
plt.show()




# Create a figure
fig = plt.figure()

# Specify that it's 3D
ax = fig.add_subplot(111, projection='3d')

# Give data a variable name
methods = data['method'].unique()

# Loop through all methods and plot each one with different colors
for method, color in zip(methods, ['r', 'g', 'b', 'y']):
    method_data = data[data['method'] == method]
    ax.scatter(method_data['opt_solve'], method_data['solve_time'], method_data['nodes'], c=color, label=method)

# Create labels
ax.set_xlabel('opt_solve')
ax.set_ylabel('solve_time')
ax.set_zlabel('nodes')

plt.legend()
plt.show()



# Create two subplots
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Variables for regression
x1 = data['opt_solve'].values.reshape(-1, 1)
y1 = data['nodes'].values.reshape(-1, 1)
x2 = data['solve_time'].values.reshape(-1, 1)
y2 = data['opt_solve'].values.reshape(-1, 1)

# Linear regression models
model1 = LinearRegression().fit(x1, y1)
model2 = LinearRegression().fit(x2, y2)

# Predictions for the line
y_pred1 = model1.predict(x1)
y_pred2 = model2.predict(x2)

# Scatter plots
ax1.scatter(x1, y1, alpha=0.5)
ax2.scatter(x2, y2, alpha=0.5)

# Line plots
ax1.plot(x1, y_pred1, color='red')
ax2.plot(x2, y_pred2, color='red')

# Set labels
ax1.set_xlabel('opt_solve')
ax1.set_ylabel('nodes')
ax2.set_xlabel('solve_time')
ax2.set_ylabel('opt_solve')

# Titles
ax1.set_title('opt_solve vs nodes')
ax2.set_title('solve_time vs opt_solve')

# Show plots
plt.tight_layout()
plt.show()



import matplotlib.pyplot as plt

# Create a scatter plot comparing the number of nodes to the optimal solve for each method
for method in data['method'].unique():
    method_data = data[data['method'] == method]
    plt.scatter(method_data['nodes'], method_data['opt_solve'], alpha=0.5, label=method)

plt.xlabel('Nodes')
plt.ylabel('Optimal Solve')
plt.title('Optimal Solve vs Number of Nodes by Method')
plt.legend()
plt.show()



import numpy as np
import matplotlib.pyplot as plt

# Unique methods
methods = data['method'].unique()

# Determine global min and max for opt_solve and nodes
opt_solve_min, opt_solve_max = data['opt_solve'].min(), data['opt_solve'].max()
nodes_min, nodes_max = data['nodes'].min(), data['nodes'].max()

# Create a new plot
plt.figure(figsize=(10, 6))

# For each method, fit a regression line and plot it
for method in methods:
    method_data = data[data['method'] == method]
    opt_solve = method_data['opt_solve']
    nodes = method_data['nodes']
    
    # Fit a line to the data
    m, b = np.polyfit(opt_solve, nodes, 1)
    
    # Plot the line
    plt.plot(opt_solve, m * opt_solve + b, label=f'{method} fit')
    
# Set the same limits for all subplots
plt.xlim([opt_solve_min, opt_solve_max])
plt.ylim([nodes_min, nodes_max])

plt.xlabel('Optimal Solve')
plt.ylabel('Nodes')
plt.title('Regression Lines for Different Methods')
plt.legend()

plt.show()
